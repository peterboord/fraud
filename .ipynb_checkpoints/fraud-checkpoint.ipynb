{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "palette = sns.color_palette()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "from scipy import interp\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "from scipy.stats import ttest_ind\n",
    "from bisect import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr_datarows = 151112, nr_datacols = 11\n",
      "nr_ipdatarows = 138846\n",
      "It is True that ipdata is sorted\n",
      "It is True that user_id differs for every row\n",
      "nr_devices = 137956\n",
      "nr_ip = 143512\n",
      "nr_non_fraud = 136961\n",
      "nr_fraud = 14151\n",
      "P(fraud) = 0.09364577267192546\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>country</th>\n",
       "      <th>time</th>\n",
       "      <th>nr_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>1251.856111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>4.984444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>136.690278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>1211.516944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_value  sex  age  class  country         time  nr_users\n",
       "0              34    1   39      0       84  1251.856111         1\n",
       "1              16    0   53      0      172     4.984444         1\n",
       "2              15    1   53      1      172     0.000278        12\n",
       "3              44    1   41      0      124   136.690278         1\n",
       "4              39    1   45      0      172  1211.516944         1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import fraud data\n",
    "url = 'Fraud_Data.csv'\n",
    "df = pd.read_csv(url)\n",
    "nr_datarows, nr_datacols = df.shape\n",
    "print 'nr_datarows = %s, nr_datacols = %s' % (nr_datarows, nr_datacols)\n",
    "#import ip address to country data\n",
    "url = 'IpAddress_to_Country.csv'\n",
    "ipdata = pd.read_csv(url)\n",
    "ipdata = ipdata.as_matrix()\n",
    "nr_ipdatarows = ipdata.shape[0]\n",
    "print 'nr_ipdatarows = %s' % nr_ipdatarows\n",
    "ip_low = ipdata[:,0].astype(float)\n",
    "ip_hi = ipdata[:,1].astype(float)\n",
    "ip_low = np.r_[ip_low, ip_hi[-1]]\n",
    "ip_country = ipdata[:,2].astype(str)\n",
    "# check sorted\n",
    "print 'It is %r that ipdata is sorted' % all(ip_low[i] < ip_low[i+1] and ip_hi[i] < ip_hi[i+1] for i in range(nr_ipdatarows - 1))\n",
    "print 'It is %r that user_id differs for every row' % (len(df['user_id']) == len(set(df['user_id'])))\n",
    "df = df.drop('user_id', axis=1)\n",
    "set_devices = set(df['device_id'])\n",
    "print 'nr_devices = %r' % len(set_devices)\n",
    "set_ip = set(df['ip_address'])\n",
    "print 'nr_ip = %r' % len(set_ip)\n",
    "print 'nr_non_fraud = %r' % sum(df['class'] == 0)\n",
    "print 'nr_fraud = %r' % sum(df['class'])\n",
    "print 'P(fraud) = %r' % (float(sum(df['class']))/nr_datarows)\n",
    "# print df.dtypes\n",
    "\n",
    "# add country to table\n",
    "country = []\n",
    "for ip in df['ip_address']:\n",
    "    ip_row = bisect(ip_low, ip) - 1\n",
    "    if ip_row == nr_ipdatarows or ip > ip_hi[ip_row]:\n",
    "        country.append('None')\n",
    "    else:\n",
    "        country.append(ip_country[ip_row])\n",
    "df['country'] = country\n",
    "\n",
    "#create new features\n",
    "#time since signup\n",
    "df['time'] = (pd.to_datetime(df['purchase_time'])-pd.to_datetime(df['signup_time']))/np.timedelta64(1, 'h')\n",
    "df = df.drop('purchase_time', axis=1)\n",
    "df = df.drop('signup_time', axis=1)\n",
    "\n",
    "# nr_device_users\n",
    "# nr_device_ip\n",
    "# nr_device_countries\n",
    "# nr_device_browsers\n",
    "\n",
    "# nr_users per device\n",
    "nr_device_users = {}\n",
    "for index, row in df.iterrows():\n",
    "    dev_id = row['device_id']\n",
    "    if dev_id not in nr_device_users:\n",
    "        nr_device_users[dev_id] = 0\n",
    "    nr_device_users[dev_id] += 1\n",
    "nr_users = []\n",
    "for dev_id in df['device_id']:\n",
    "    nr_users.append(nr_device_users[dev_id])\n",
    "df['nr_users'] = nr_users\n",
    "nr_device_users.clear()\n",
    "\n",
    "# drop variables not used for classification\n",
    "df = df.drop('device_id', axis=1)\n",
    "df = df.drop('source', axis=1)\n",
    "df = df.drop('browser', axis=1)\n",
    "df = df.drop('ip_address', axis=1)\n",
    "\n",
    "# change categorical to integer\n",
    "df['sex'] = df['sex'].astype('category')\n",
    "df['sex'] = df['sex'].cat.codes\n",
    "df['country'] = df['country'].astype('category')\n",
    "df['country'] = df['country'].cat.codes\n",
    "\n",
    "print df.dtypes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>time</th>\n",
       "      <th>nr_users</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.929418</td>\n",
       "      <td>0.583078</td>\n",
       "      <td>33.122356</td>\n",
       "      <td>122.144800</td>\n",
       "      <td>1441.994052</td>\n",
       "      <td>1.120071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.993004</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>33.318281</td>\n",
       "      <td>122.557628</td>\n",
       "      <td>673.289542</td>\n",
       "      <td>7.145926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       purchase_value       sex        age     country         time  nr_users\n",
       "class                                                                        \n",
       "0           36.929418  0.583078  33.122356  122.144800  1441.994052  1.120071\n",
       "1           36.993004  0.596000  33.318281  122.557628   673.289542  7.145926"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchase_value      int64\n",
      "sex                  int8\n",
      "age                 int64\n",
      "class               int64\n",
      "country             int16\n",
      "time              float64\n",
      "nr_users            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   purchase_value sex  age  class        country         time  nr_users\n",
      "0              34   M   39      0          Japan  1251.856111         1\n",
      "1              16   F   53      0  United States     4.984444         1\n",
      "2              15   M   53      1  United States     0.000278        12\n",
      "3              44   M   41      0           None   136.690278         1\n",
      "4              39   M   45      0  United States  1211.516944         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pboord/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/pboord/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/pboord/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/pboord/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>country</th>\n",
       "      <th>time</th>\n",
       "      <th>nr_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1251.856111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.984444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>136.690278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1211.516944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_value  sex  age  class  country         time  nr_users\n",
       "0              34    1   39      0        0  1251.856111         1\n",
       "1              16    0   53      0        2     4.984444         1\n",
       "2              15    1   53      1        2     0.000278        12\n",
       "3              44    1   41      0        1   136.690278         1\n",
       "4              39    1   45      0        2  1211.516944         1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfh = df.head()\n",
    "print dfh\n",
    "dfh['sex'] = dfh['sex'].astype('category')\n",
    "dfh['sex'] = dfh['sex'].cat.codes\n",
    "dfh['country'] = dfh['country'].astype('category')\n",
    "dfh['country'] = dfh['country'].cat.codes\n",
    "dfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'applymap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-31a8a26a0818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdfh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pboord/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'applymap'"
     ]
    }
   ],
   "source": [
    "dfh = df.head()\n",
    "dfh['sex'] = dfh['sex'].applymap(lambda x: (x == 'M')*1)\n",
    "dfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .cat accessor with a 'category' dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f2245b33b320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/pboord/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2738\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[1;32m   2739\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 2740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pboord/anaconda2/lib/python2.7/site-packages/pandas/core/base.pyc\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;31m# this ensures that Series.str.<method> is well defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccessor_cls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pboord/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_make_cat_accessor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2752\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_cat_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2754\u001b[0;31m             raise AttributeError(\"Can only use .cat accessor with a \"\n\u001b[0m\u001b[1;32m   2755\u001b[0m                                  \"'category' dtype\")\n\u001b[1;32m   2756\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mCategoricalAccessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .cat accessor with a 'category' dtype"
     ]
    }
   ],
   "source": [
    "dfh['sex'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfh['sex'] =dfh['sex'].apply(lambda x: x.cat.codes)\n",
    "dfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>\n",
    "Preprocessed Data:\n",
    "</b>\n",
    "\n",
    "1) Checked for duplicate rows. Duplicate rows are likely to be the same person entered twice and not separate entries. \n",
    "\n",
    "2) Dropped rows missing data. An alternative to dropping this row would be to infer the missing value using the mean value of the column. There was 1 row with non-numeric or missing data. \n",
    "\n",
    "3) Drop unique identifiers.\n",
    "\n",
    "4) Convert binary data to 1s and 0s.\n",
    "\n",
    "5) Create new features. Include time since sign up by subtracting sign up time from purchase time. Include frequncy of each user id, device id and ip address to see how many times each is used.\n",
    "\n",
    "6) Check if continuous or binary features are correlated. We can improve model performance by removing correlated variables. An alternative to removing the column would be to perform principal component analysis, but we lose interpretability.\n",
    "\n",
    "7) Visualize data. What does the distribution look like? Are some features categorical?\n",
    "\n",
    "8) Convert categorical data to dummy variables\n",
    "\n",
    "<br>\n",
    "<b>\n",
    "With more time I would consider the following pre-processing steps:\n",
    "</b>\n",
    "\n",
    "9) Transform non-normal features. We can improve models by normalizing features.\n",
    "\n",
    "10) Identify and remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop duplicate rows\n",
    "df = data\n",
    "df['country'] = df['country'].astype(str)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "#drop unique identifiers\n",
    "df = df.drop('user_id', axis=1)\n",
    "df = df.drop('country', axis=1)\n",
    "\n",
    "#convert to binary \n",
    "for col in ['class', 'sex']:\n",
    "    dummy = pd.get_dummies(df[col]).astype(int)\n",
    "    df[col] = dummy.ix[:,1]\n",
    "    \n",
    "#create new features\n",
    "#time since signup\n",
    "df['time'] = (pd.to_datetime(df['purchase_time'])-pd.to_datetime(df['signup_time']))/np.timedelta64(1, 'h')\n",
    "df = df.drop('purchase_time', axis=1)\n",
    "df = df.drop('signup_time', axis=1)\n",
    "#multiple users\n",
    "df['device_count'] = df.groupby(['device_id'])['device_id'].transform('count')\n",
    "df['ip_count'] = df.groupby(['ip_address'])['ip_address'].transform('count')\n",
    "df = df.drop('device_id', axis=1)\n",
    "df = df.drop('ip_address', axis=1)\n",
    "\n",
    "#drop one of two correlated features\n",
    "da = df[['purchase_value', 'age', 'time', 'ip_count', 'device_count']]\n",
    "cor = da.astype('float64').corr()\n",
    "print(cor)\n",
    "df = df.drop('device_count', axis=1)\n",
    "\n",
    "#visualize histograms\n",
    "df[df.columns].hist(figsize=(30,30))\n",
    "\n",
    "#convert to categorical data to dummy columns\n",
    "for col in ['source', 'browser']:\n",
    "    df[col] = df[col].astype('category')\n",
    "df = pd.get_dummies(df)\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> \n",
    "Split Data \n",
    "</b>\n",
    "\n",
    "I randomly split data into independent training and test sets. The split was 70/30 between the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = df['class']\n",
    "X = df.drop(['class'], axis=1)\n",
    "X = X.as_matrix()\n",
    "\n",
    "#split data on unique ids\n",
    "rs = ShuffleSplit(n_splits=2, test_size=.30, random_state=0)\n",
    "for train_index, test_index in rs.split(X):\n",
    "            X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "Model selection\n",
    "</b>\n",
    "\n",
    "I built two models: logistic regression + lasso and random forest. I changed the class weights to account for the imbalanced data set.\n",
    "\n",
    "The area under the curve for logistic regression + lasso (AUC = 0.77) is higher than that of random forest (AUC = 0.77). The two models perform similarly.\n",
    "\n",
    "<br>\n",
    "<b>\n",
    "With more time, I would do the following to improve model performance.\n",
    "</b>\n",
    "\n",
    "1) Optimize parameters <br><br>\n",
    "2) Feature selection for random forest <br><br>\n",
    "3) Test more models <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression + Lasso \n",
    "clf = linear_model.LogisticRegression(C=1, penalty='l1', tol=1e-6, class_weight='balanced')\n",
    "tmp = clf.fit(X_train, Y_train)\n",
    "clf_y_score = clf.fit(X_train, Y_train).predict_proba(X_test)[:, 1]\n",
    "y_pred = clf.predict(X_test)\n",
    "auc = roc_auc_score(Y_test, y_pred)\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Logistic Regression + Lasso\")\n",
    "print(\"AUC: \"+str(auc))\n",
    "print(\"\\nConfusion Matrix: \")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "tmp = rf.fit(X_train, Y_train)\n",
    "rf_y_score = rf.fit(X_train, Y_train).predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "auc = roc_auc_score(Y_test, y_pred)\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Random Forest\")\n",
    "print(\"AUC: \"+str(auc))\n",
    "print(\"\\nConfusion Matrix: \")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feature Importance </b>\n",
    "\n",
    "The most important variable for predicting fraud is the source. It may be that some sources are easier to commit fraud through. It may be useful to have different thresholds for declaring fraud for different sources.\n",
    "<br><br>\n",
    "The second most important variables for predicting fraud are the number of transactions from the same ip address (with different user ids). This is also correlated with device id (with different user ids). The average number of these transactions for those flagged as fradulent is significant higher than that of the non-flagged grouped according to a t-test with a p-value of less than 0.05. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get variable importance from random forest\n",
    "importance = [abs(x) for x in clf.coef_[0]]\n",
    "importance = list(zip(list(df.columns[1:]),importance))\n",
    "importance = sorted(importance, key=lambda x: x[1])\n",
    "importance = importance[::-1]\n",
    "print('Importance:')\n",
    "for imp in importance:\n",
    "    print(str(imp[0])+' = '+str(imp[1]))\n",
    "\n",
    "#test significance\n",
    "dfsplit = [rows for _, rows in df.groupby('class')]\n",
    "t, p = ttest_ind(dfsplit[0]['ip_count'], dfsplit[1]['ip_count'], equal_var=False)\n",
    "print('\\n\\n==========================\\n\\n')\n",
    "print(\"T-Test:\")\n",
    "print(\"p: \"+str(p))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#plot most important variables\n",
    "plt.figure()\n",
    "sns.barplot(x=\"class\", y=\"ip_count\", data=df)\n",
    "sns.plt.title('Transaction Frequency from Same IP Address')\n",
    "plt.show()\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot ROC curve\n",
    "clf_fpr, clf_tpr, clf_auc = roc_curve(Y_test, clf_y_score)\n",
    "rf_fpr, rf_tpr, rf_auc = roc_curve(Y_test, rf_y_score)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(clf_fpr, clf_tpr, 'r', label='Logistic + Lasso')\n",
    "plt.plot(rf_fpr, rf_tpr, 'b', label='Random Forest')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
